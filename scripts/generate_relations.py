#!/usr/bin/env python3
"""
MHive ê´€ê³„ ìë™ ìƒì„± ìŠ¤í¬ë¦½íŠ¸
ì‚¬ê±´ë“¤ ê°„ì˜ ê´€ê³„ë¥¼ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ê³  ìƒì„±í•©ë‹ˆë‹¤.
"""

import json
import os
from typing import Dict, Any, List, Set, Tuple
from datetime import datetime
from collections import defaultdict
import re

# ì„¤ì •
INPUT_FILE = os.path.join(os.path.dirname(__file__), '..', 'data', 'processed', 'incidents_translated.json')
OUTPUT_FILE = os.path.join(os.path.dirname(__file__), '..', 'data', 'processed', 'incidents_with_relations.json')


def parse_year(date_str: str) -> int:
    """ë‚ ì§œ ë¬¸ìì—´ì—ì„œ ì—°ë„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        if date_str.startswith('-'):
            return -int(date_str.split('-')[1])
        return int(date_str.split('-')[0])
    except:
        return 2000


def get_region(location: str) -> str:
    """ìœ„ì¹˜ì—ì„œ ì§€ì—­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    regions = {
        "í•œêµ­": ["í•œêµ­", "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì§„ë„", "í™”ì„±"],
        "ì¼ë³¸": ["ì¼ë³¸", "ë„ì¿„", "ì˜¤ì‚¬ì¹´", "í›„ì¿ ì‹œë§ˆ", "ë„í˜¸ì¿ "],
        "ì¤‘êµ­": ["ì¤‘êµ­", "ë² ì´ì§•", "ìƒí•˜ì´", "ë‚œì§•", "íƒ•ì‚°", "ì“°ì´¨"],
        "ë¯¸êµ­": ["ë¯¸êµ­", "ë‰´ìš•", "ì›Œì‹±í„´", "ìº˜ë¦¬í¬ë‹ˆì•„", "í…ì‚¬ìŠ¤", "ë¡œìŠ¤ì•¤ì ¤ë ˆìŠ¤", "ë‰´ì €ì§€", "ì˜¤í´ë¼í˜¸ë§ˆ", "ë„¤ë°”ë‹¤", "ë‰´ë©•ì‹œì½”"],
        "ìœ ëŸ½": ["ì˜êµ­", "í”„ë‘ìŠ¤", "ë…ì¼", "ìŠ¤í˜ì¸", "ì´íƒˆë¦¬ì•„", "ëŸ°ë˜", "íŒŒë¦¬", "ë§ˆë“œë¦¬ë“œ", "ë‹ˆìŠ¤", "ë³´ìŠ¤ë‹ˆì•„"],
        "ë™ë‚¨ì•„": ["ì¸ë„ë„¤ì‹œì•„", "íƒœêµ­", "ë² íŠ¸ë‚¨", "í•„ë¦¬í•€", "ë§ë ˆì´ì‹œì•„", "ìŠ¤ë¦¬ë‘ì¹´"],
        "ì¤‘ë™": ["ì´ë€", "ì´ë¼í¬", "ì‹œë¦¬ì•„", "ë ˆë°”ë…¼", "íŠ€ë¥´í‚¤ì˜ˆ", "ë² ì´ë£¨íŠ¸", "í…Œí—¤ë€"],
        "ì•„í”„ë¦¬ì¹´": ["ë¥´ì™„ë‹¤", "ì´ì§‘íŠ¸", "ë‚¨ì•„í”„ë¦¬ì¹´"],
        "ë‚¨ë¯¸": ["ë¸Œë¼ì§ˆ", "í˜ë£¨", "ì¹ ë ˆ", "ì•„ì´í‹°"],
        "ëŸ¬ì‹œì•„": ["ëŸ¬ì‹œì•„", "ì†Œë ¨", "ìš°í¬ë¼ì´ë‚˜", "ìš°ë„", "ì‚¬í• ë¦°"],
        "ì¸ë„": ["ì¸ë„", "ë­„ë°”ì´", "ë³´íŒ”", "ë°©ê¸€ë¼ë°ì‹œ"],
        "ìº„ë³´ë””ì•„": ["ìº„ë³´ë””ì•„"],
        "ëŒ€ì–‘": ["ëŒ€ì„œì–‘", "íƒœí‰ì–‘", "ì¸ë„ì–‘", "ë¶ëŒ€ì„œì–‘"],
    }

    location_lower = location.lower()
    for region, keywords in regions.items():
        if any(kw.lower() in location_lower for kw in keywords):
            return region
    return "ê¸°íƒ€"


def calculate_similarity_score(inc1: Dict, inc2: Dict) -> Tuple[float, str]:
    """ë‘ ì‚¬ê±´ ê°„ì˜ ìœ ì‚¬ë„ ì ìˆ˜ì™€ ê´€ê³„ ìœ í˜•ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
    score = 0.0
    relation_types = []

    # 1. ê°™ì€ ì¹´í…Œê³ ë¦¬ (+2ì )
    if inc1['category'] == inc2['category']:
        score += 2.0
        category_names = {
            'disaster': 'ìì—°ì¬í•´',
            'accident': 'ì‚¬ê³ ',
            'terrorism': 'í…ŒëŸ¬',
            'crime': 'ë²”ì£„',
            'mystery': 'ë¯¸ìŠ¤í„°ë¦¬',
            'conspiracy': 'ìŒëª¨ë¡ ',
            'unsolved': 'ë¯¸ì œì‚¬ê±´',
        }
        relation_types.append(f"ë™ì¼ ìœ í˜•: {category_names.get(inc1['category'], inc1['category'])}")

    # 2. ê°™ì€ ì§€ì—­ (+3ì )
    region1 = get_region(inc1.get('location', ''))
    region2 = get_region(inc2.get('location', ''))
    if region1 == region2 and region1 != "ê¸°íƒ€":
        score += 3.0
        relation_types.append(f"ë™ì¼ ì§€ì—­: {region1}")

    # 3. ë¹„ìŠ·í•œ ì‹œê¸° (Â±5ë…„ ë‚´ +1ì , Â±2ë…„ ë‚´ +2ì )
    year1 = parse_year(inc1.get('date', ''))
    year2 = parse_year(inc2.get('date', ''))
    year_diff = abs(year1 - year2)

    if year_diff <= 2:
        score += 2.0
        relation_types.append("ë™ì‹œëŒ€ ì‚¬ê±´")
    elif year_diff <= 5:
        score += 1.0
        relation_types.append("ìœ ì‚¬ ì‹œê¸°")

    # 4. ê³µí†µ íƒœê·¸ (íƒœê·¸ë‹¹ +1ì )
    tags1 = set(inc1.get('tags', []))
    tags2 = set(inc2.get('tags', []))
    common_tags = tags1 & tags2

    if common_tags:
        score += len(common_tags) * 1.0
        relation_types.append(f"ê³µí†µ íƒœê·¸: {', '.join(list(common_tags)[:2])}")

    # 5. ìœ ì‚¬í•œ ì‚¬ìƒì ê·œëª¨ (+1ì )
    cas1 = inc1.get('casualties', {})
    cas2 = inc2.get('casualties', {})
    if cas1 and cas2:
        deaths1 = cas1.get('deaths', 0)
        deaths2 = cas2.get('deaths', 0)
        if deaths1 > 0 and deaths2 > 0:
            ratio = min(deaths1, deaths2) / max(deaths1, deaths2)
            if ratio > 0.3:
                score += 1.0
                relation_types.append("ìœ ì‚¬ í”¼í•´ ê·œëª¨")

    # 6. íŠ¹ìˆ˜ ê´€ê³„ íŒ¨í„´
    # ì›ì „ ì‚¬ê³ 
    if 'ì›ì „' in str(inc1.get('tags', [])) and 'ì›ì „' in str(inc2.get('tags', [])):
        score += 2.0
        relation_types = ["ì›ì „ ì‚¬ê³ "]

    # í•­ê³µ ì‚¬ê³ 
    if 'í•­ê³µ' in str(inc1.get('tags', [])) and 'í•­ê³µ' in str(inc2.get('tags', [])):
        score += 2.0
        relation_types = ["í•­ê³µ ì‚¬ê³ "]

    # í•´ìƒ ì‚¬ê³ 
    if any(t in str(inc1.get('tags', [])) for t in ['í•´ìƒ', 'ì¹¨ëª°', 'ì„ ë°•']) and \
       any(t in str(inc2.get('tags', [])) for t in ['í•´ìƒ', 'ì¹¨ëª°', 'ì„ ë°•']):
        score += 2.0
        relation_types = ["í•´ìƒ ì°¸ì‚¬"]

    # ì—°ì‡„ì‚´ì¸
    if 'ì—°ì‡„ì‚´ì¸' in str(inc1.get('title', '') + str(inc1.get('tags', []))) and \
       'ì—°ì‡„ì‚´ì¸' in str(inc2.get('title', '') + str(inc2.get('tags', []))):
        score += 3.0
        relation_types = ["ì—°ì‡„ì‚´ì¸ ì‚¬ê±´"]

    # ê°€ì¥ ì í•©í•œ ê´€ê³„ ì„ íƒ
    if relation_types:
        # ìš°ì„ ìˆœìœ„: íŠ¹ìˆ˜ ê´€ê³„ > ì¹´í…Œê³ ë¦¬ > ì§€ì—­ > íƒœê·¸
        relation = relation_types[-1]  # ë§ˆì§€ë§‰ ì¶”ê°€ëœ ê²ƒì´ ë³´í†µ ë” êµ¬ì²´ì 
    else:
        relation = "ê´€ë ¨ ì‚¬ê±´"

    return score, relation


def generate_relations(incidents: List[Dict]) -> List[Dict]:
    """ëª¨ë“  ì‚¬ê±´ ìŒì— ëŒ€í•´ ê´€ê³„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    relations = []
    seen_pairs = set()

    print(f"  ë¶„ì„ ì¤‘: {len(incidents)}ê°œ ì‚¬ê±´, {len(incidents) * (len(incidents) - 1) // 2}ê°œ ìŒ")

    for i, inc1 in enumerate(incidents):
        for j, inc2 in enumerate(incidents):
            if i >= j:
                continue

            # ì¤‘ë³µ ë°©ì§€
            pair = (min(inc1['id'], inc2['id']), max(inc1['id'], inc2['id']))
            if pair in seen_pairs:
                continue
            seen_pairs.add(pair)

            # ìœ ì‚¬ë„ ê³„ì‚°
            score, relation = calculate_similarity_score(inc1, inc2)

            # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ ê´€ê³„ ì¶”ê°€
            if score >= 3.0:
                relations.append({
                    'from': inc1['id'],
                    'to': inc2['id'],
                    'relation': relation,
                    'score': score
                })

    # ì ìˆ˜ ë†’ì€ ìˆœ ì •ë ¬
    relations.sort(key=lambda x: x['score'], reverse=True)

    # ê° ë…¸ë“œë‹¹ ìµœëŒ€ ì—°ê²° ìˆ˜ ì œí•œ (ë„ˆë¬´ ë³µì¡í•´ì§€ì§€ ì•Šê²Œ)
    connection_count = defaultdict(int)
    max_connections = 5
    filtered_relations = []

    for rel in relations:
        if connection_count[rel['from']] < max_connections and \
           connection_count[rel['to']] < max_connections:
            filtered_relations.append({
                'from': rel['from'],
                'to': rel['to'],
                'relation': rel['relation']
            })
            connection_count[rel['from']] += 1
            connection_count[rel['to']] += 1

    return filtered_relations


def update_related_incidents(incidents: List[Dict], relations: List[Dict]) -> List[Dict]:
    """ê° ì‚¬ê±´ì˜ relatedIncidents í•„ë“œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    related_map = defaultdict(list)

    for rel in relations:
        related_map[rel['from']].append(rel['to'])
        related_map[rel['to']].append(rel['from'])

    for incident in incidents:
        incident['relatedIncidents'] = related_map.get(incident['id'], [])

    return incidents


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”— MHive ê´€ê³„ ìƒì„± ì‹œì‘...")

    # ì…ë ¥ íŒŒì¼ í™•ì¸
    input_file = INPUT_FILE
    if not os.path.exists(input_file):
        # ë²ˆì—­ë˜ì§€ ì•Šì€ ì›ë³¸ íŒŒì¼ ì‹œë„
        input_file = os.path.join(os.path.dirname(__file__), '..', 'data', 'raw', 'incidents_raw.json')
        if not os.path.exists(input_file):
            print(f"âŒ ì…ë ¥ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € fetch_disasters.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return

    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    incidents = data.get('incidents', [])
    print(f"   ì…ë ¥ ì‚¬ê±´ ìˆ˜: {len(incidents)}ê°œ")

    # ê´€ê³„ ìƒì„±
    relations = generate_relations(incidents)
    print(f"   ìƒì„±ëœ ê´€ê³„: {len(relations)}ê°œ")

    # relatedIncidents ì—…ë°ì´íŠ¸
    incidents = update_related_incidents(incidents, relations)

    # ê²°ê³¼ ì €ì¥
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    output_data = {
        'incidents': incidents,
        'relations': relations
    }

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ê´€ê³„ ìƒì„± ì™„ë£Œ!")
    print(f"   ì¶œë ¥ íŒŒì¼: {OUTPUT_FILE}")

    # í†µê³„
    categories = defaultdict(int)
    for inc in incidents:
        categories[inc['category']] += 1

    print("\nğŸ“Š ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
    for cat, count in sorted(categories.items(), key=lambda x: -x[1]):
        print(f"   - {cat}: {count}ê°œ")


if __name__ == "__main__":
    main()
