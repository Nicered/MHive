#!/usr/bin/env python3
"""
OpenFEMA ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
ë¯¸êµ­ ì¬ë‚œ ì„ ì–¸ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

import json
import requests
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from tqdm import tqdm
import os
from datetime import datetime

OUTPUT_DIR = os.path.join(os.path.dirname(__file__), '..', 'data', 'sources')
FEMA_API = "https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries"

# ë¯¸êµ­ ì£¼ ì½”ë“œ -> ì´ë¦„ ë§¤í•‘
US_STATES = {
    'AL': 'Alabama', 'AK': 'Alaska', 'AZ': 'Arizona', 'AR': 'Arkansas',
    'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DE': 'Delaware',
    'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'ID': 'Idaho',
    'IL': 'Illinois', 'IN': 'Indiana', 'IA': 'Iowa', 'KS': 'Kansas',
    'KY': 'Kentucky', 'LA': 'Louisiana', 'ME': 'Maine', 'MD': 'Maryland',
    'MA': 'Massachusetts', 'MI': 'Michigan', 'MN': 'Minnesota', 'MS': 'Mississippi',
    'MO': 'Missouri', 'MT': 'Montana', 'NE': 'Nebraska', 'NV': 'Nevada',
    'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NY': 'New York',
    'NC': 'North Carolina', 'ND': 'North Dakota', 'OH': 'Ohio', 'OK': 'Oklahoma',
    'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina',
    'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah',
    'VT': 'Vermont', 'VA': 'Virginia', 'WA': 'Washington', 'WV': 'West Virginia',
    'WI': 'Wisconsin', 'WY': 'Wyoming', 'DC': 'Washington D.C.', 'PR': 'Puerto Rico',
    'VI': 'U.S. Virgin Islands', 'GU': 'Guam', 'AS': 'American Samoa',
}

# ì¬ë‚œ ìœ í˜• ë§¤í•‘
INCIDENT_TYPE_MAP = {
    'Fire': ('disaster', 'í™”ì¬'),
    'Flood': ('disaster', 'í™ìˆ˜'),
    'Hurricane': ('disaster', 'í—ˆë¦¬ì¼€ì¸'),
    'Severe Storm': ('disaster', 'í­í’'),
    'Tornado': ('disaster', 'í† ë„¤ì´ë„'),
    'Earthquake': ('disaster', 'ì§€ì§„'),
    'Snow': ('disaster', 'í­ì„¤'),
    'Severe Ice Storm': ('disaster', 'ë¹™ì„¤'),
    'Typhoon': ('disaster', 'íƒœí’'),
    'Volcanic Eruption': ('disaster', 'í™”ì‚°í­ë°œ'),
    'Tsunami': ('disaster', 'ì“°ë‚˜ë¯¸'),
    'Coastal Storm': ('disaster', 'í•´ì•ˆí­í’'),
    'Dam/Levee Break': ('accident', 'ëŒë¶•ê´´'),
    'Mud/Landslide': ('disaster', 'ì‚°ì‚¬íƒœ'),
    'Terrorist': ('terrorism', 'í…ŒëŸ¬'),
    'Toxic Substances': ('accident', 'ìœ í•´ë¬¼ì§ˆ'),
    'Biological': ('disaster', 'ìƒë¬¼ì¬í•´'),
    'Chemical': ('accident', 'í™”í•™ì‚¬ê³ '),
    'Human Cause': ('accident', 'ì¸ì¬'),
    'Other': ('disaster', 'ê¸°íƒ€'),
    'Freezing': ('disaster', 'í•œíŒŒ'),
    'Drought': ('disaster', 'ê°€ë­„'),
}


def fetch_fema_data(skip: int = 0, top: int = 1000) -> List[Dict]:
    """OpenFEMA APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    params = {
        '$skip': skip,
        '$top': top,
        '$orderby': 'declarationDate desc',
        '$format': 'json',
    }

    try:
        response = requests.get(FEMA_API, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        return data.get('DisasterDeclarationsSummaries', [])
    except Exception as e:
        print(f"Error fetching FEMA data: {e}")
        return []


def parse_date(date_str: Optional[str]) -> str:
    """ISO ë‚ ì§œ ë¬¸ìì—´ì„ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    if not date_str:
        return ""
    try:
        dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        return dt.strftime('%Y-%m-%d')
    except:
        return date_str[:10] if date_str else ""


def determine_era(date_str: str) -> str:
    """ë‚ ì§œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‹œëŒ€ë¥¼ ê²°ì •í•©ë‹ˆë‹¤."""
    try:
        year = int(date_str.split("-")[0])
        if year < 1900:
            return "modern"
        else:
            return "contemporary"
    except:
        return "contemporary"


def transform_to_incident(item: Dict, incident_id: int) -> Dict:
    """FEMA ë°ì´í„°ë¥¼ MHive Incident í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    incident_type = item.get('incidentType', 'Other')
    category, tag = INCIDENT_TYPE_MAP.get(incident_type, ('disaster', 'ê¸°íƒ€'))

    state_code = item.get('state', '')
    state_name = US_STATES.get(state_code, state_code)
    designated_area = item.get('designatedArea', '')
    location = f"{designated_area}, {state_name}, USA" if designated_area else f"{state_name}, USA"

    declaration_date = parse_date(item.get('declarationDate'))
    incident_begin = parse_date(item.get('incidentBeginDate'))
    incident_end = parse_date(item.get('incidentEndDate'))

    date = incident_begin or declaration_date

    title = item.get('declarationTitle', f"{incident_type} in {state_name}")

    # ìš”ì•½ ë° ì„¤ëª… ìƒì„±
    summary = f"{item.get('fyDeclared', '')}ë…„ {state_name}ì—ì„œ ë°œìƒí•œ {incident_type} ì¬ë‚œ. "
    summary += f"FEMA ì¬ë‚œ ë²ˆí˜¸: {item.get('disasterNumber', 'N/A')}. "
    summary += f"ì¬ë‚œ ì„ ì–¸ì¼: {declaration_date}."

    description = f"## ê°œìš”\n\n{title}\n\n"
    description += f"**ì¬ë‚œ ìœ í˜•**: {incident_type}\n"
    description += f"**ìœ„ì¹˜**: {location}\n"
    description += f"**ì¬ë‚œ ì‹œì‘ì¼**: {incident_begin or 'N/A'}\n"
    if incident_end:
        description += f"**ì¬ë‚œ ì¢…ë£Œì¼**: {incident_end}\n"
    description += f"\n## FEMA ì •ë³´\n\n"
    description += f"- ì¬ë‚œ ë²ˆí˜¸: {item.get('disasterNumber', 'N/A')}\n"
    description += f"- ì„ ì–¸ ìœ í˜•: {item.get('declarationType', 'N/A')}\n"
    description += f"- FEMA ì„ ì–¸ ë¬¸ìì—´: {item.get('femaDeclarationString', 'N/A')}\n"

    # íƒœê·¸
    tags = ['ì¬ë‚œ', 'ë¯¸êµ­', tag]
    if item.get('declarationType') == 'DR':
        tags.append('ëŒ€í˜•ì¬ë‚œ')
    elif item.get('declarationType') == 'EM':
        tags.append('ë¹„ìƒì‚¬íƒœ')

    return {
        'id': incident_id,
        'title': title,
        'category': category,
        'era': determine_era(date),
        'date': date,
        'location': location,
        'summary': summary[:400],
        'description': description[:3000],
        'timeline': [],
        'theories': [],
        'tags': list(set(tags)),
        'sources': [{
            'name': 'OpenFEMA',
            'url': f"https://www.fema.gov/disaster/{item.get('disasterNumber', '')}"
        }],
        'relatedIncidents': [],
        'images': [],
        'casualties': None,
        'coordinates': None,
        'status': 'resolved' if incident_end else 'ongoing',
        'originalId': item.get('id'),
        'femaDisasterNumber': item.get('disasterNumber'),
    }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ›ï¸ OpenFEMA ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")

    all_items = []
    skip = 0
    batch_size = 1000
    max_items = 5000  # ìµœëŒ€ 5000ê°œ ìˆ˜ì§‘

    with tqdm(total=max_items, desc="FEMA ë°ì´í„° ìˆ˜ì§‘") as pbar:
        while len(all_items) < max_items:
            items = fetch_fema_data(skip=skip, top=batch_size)
            if not items:
                break
            all_items.extend(items)
            pbar.update(len(items))
            skip += batch_size

            if len(items) < batch_size:
                break

    print(f"\nğŸ“Š ì´ {len(all_items)}ê°œ ì›ë³¸ ë°ì´í„° ìˆ˜ì§‘")

    # ì¤‘ë³µ ì œê±° (disasterNumber ê¸°ì¤€)
    seen = set()
    unique_items = []
    for item in all_items:
        disaster_num = item.get('disasterNumber')
        if disaster_num and disaster_num not in seen:
            seen.add(disaster_num)
            unique_items.append(item)

    print(f"   ì¤‘ë³µ ì œê±° í›„: {len(unique_items)}ê°œ")

    # MHive í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    incidents = []
    for i, item in enumerate(tqdm(unique_items, desc="ë°ì´í„° ë³€í™˜")):
        incident = transform_to_incident(item, i + 1)
        incidents.append(incident)

    # ê²°ê³¼ ì €ì¥
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_file = os.path.join(OUTPUT_DIR, "fema_disasters.json")

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump({
            'source': 'OpenFEMA',
            'collected_at': datetime.now().isoformat(),
            'total_count': len(incidents),
            'incidents': incidents
        }, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ì™„ë£Œ! {len(incidents)}ê°œ ì‚¬ê±´ ì €ì¥ë¨")
    print(f"   ì¶œë ¥ íŒŒì¼: {output_file}")

    # í†µê³„
    type_stats = {}
    for inc in incidents:
        cat = inc['category']
        type_stats[cat] = type_stats.get(cat, 0) + 1

    print("\nğŸ“ˆ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
    for cat, count in sorted(type_stats.items(), key=lambda x: -x[1]):
        print(f"   - {cat}: {count}ê°œ")


if __name__ == "__main__":
    main()
